{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['business', 'entertainment', 'politics', 'sport', 'tech'])\n"
     ]
    }
   ],
   "source": [
    "#access the bbc folder and assign a dictionary of {directory:files}\n",
    "\n",
    "import os\n",
    "\n",
    "source_path = '../bbc/'\n",
    "mapping = {}\n",
    "# looping through directory\n",
    "for i in sorted(os.listdir(source_path)):\n",
    "    # checking if it is directory or not\n",
    "    if os.path.isdir(source_path+i):\n",
    "        # creating the dictionary with class as key and first 300 files as key\n",
    "        mapping[i] = sorted(os.listdir(source_path+i))[:50]\n",
    "print(mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label or class or target list\n",
    "label = []\n",
    "\n",
    "# file name\n",
    "file_name = []\n",
    "\n",
    "# text file data list\n",
    "data = []\n",
    "\n",
    "# unpacking and iterating through dictionary\n",
    "for i, j in mapping.items():\n",
    "    # iterating through list of files for each class\n",
    "    for k in j:\n",
    "        # appending labels/class/target\n",
    "        label.append(i)\n",
    "        file_name.append(k)\n",
    "        # reading the file and appending to data list\n",
    "        data.append(open(source_path+i+\"/\"+k, encoding=\"cp1252\").read().replace(\"\\n\", \" \"))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to amazon comprehend\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "client = boto3.client(service_name='comprehend', region_name='us-east-1')\n",
    "role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the amazon detect_entities and store label and text\n",
    "\n",
    "aws_ent_label = []\n",
    "aws_ent_text = []\n",
    "for txt_data in data:\n",
    "    #Entities\n",
    "\n",
    "    response = client.detect_entities(\n",
    "        Text=txt_data[:5000],\n",
    "        LanguageCode='en'\n",
    "    )\n",
    "    #print(response)\n",
    "    aws_ent_label.append([x['Type'] for x in response['Entities']])\n",
    "    aws_ent_text.append([x['Text'] for x in response['Entities']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare spacy entity recognition with comprehend\n",
    "\n",
    "#install spacy\n",
    "\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy model\n",
    "\n",
    "import en_core_web_sm\n",
    "\n",
    "en_nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a spacy doc and access entities via doc.ents\n",
    "\n",
    "spacy_ent_label = []\n",
    "spacy_ent_text = []\n",
    "for txt_data in data:\n",
    "    doc = en_nlp(t xt_data[:5000])\n",
    "    spacy_ent_label.append([ent.label_ for ent in doc.ents])\n",
    "    spacy_ent_text.append([ent.text for ent in doc.ents])\n",
    "\n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>aws_entity</th>\n",
       "      <th>aws_text</th>\n",
       "      <th>spacy_entity</th>\n",
       "      <th>spacy_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>[ORGANIZATION, LOCATION, ORGANIZATION, QUANTIT...</td>\n",
       "      <td>[Time Warner, US, TimeWarner, 76%, $1.13bn, £6...</td>\n",
       "      <td>[ORG, GPE, ORG, PERCENT, MONEY, ORG, DATE, MON...</td>\n",
       "      <td>[Time Warner, US, TimeWarner, 76%, 1.13bn, Â£6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>[PERSON, QUANTITY, ORGANIZATION, LOCATION, PER...</td>\n",
       "      <td>[Greenspan, almost three months, Federal Reser...</td>\n",
       "      <td>[PERSON, DATE, ORG, GPE, PERSON, GPE, GPE, MON...</td>\n",
       "      <td>[Greenspan, almost three months, the Federal R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>[ORGANIZATION, OTHER, ORGANIZATION, QUANTITY, ...</td>\n",
       "      <td>[Yukos, Russian, Yukos, $900m, Â£479m, Rosneft...</td>\n",
       "      <td>[NORP, PRODUCT, MONEY, ORG, ORG, GPE, MONEY, G...</td>\n",
       "      <td>[Russian, Yukos, $900m, State, Rosneft, Yugans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>[ORGANIZATION, ORGANIZATION, QUANTITY, QUANTIT...</td>\n",
       "      <td>[BA, British Airways, 40%, three months, 31 De...</td>\n",
       "      <td>[ORG, PERCENT, DATE, MONEY, GPE, DATE, PERSON,...</td>\n",
       "      <td>[BA, 40%, the three months to 31 December 2004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>[ORGANIZATION, ORGANIZATION, LOCATION, ORGANIZ...</td>\n",
       "      <td>[Pernod, Domecq, UK, Allied Domecq, France, Pe...</td>\n",
       "      <td>[ORG, GPE, ORG, GPE, ORG, ORG, ORG, NORP, ORG,...</td>\n",
       "      <td>[Domecq  , UK, Allied Domecq, France, Pernod R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label filename                                         aws_entity  \\\n",
       "0  business  001.txt  [ORGANIZATION, LOCATION, ORGANIZATION, QUANTIT...   \n",
       "1  business  002.txt  [PERSON, QUANTITY, ORGANIZATION, LOCATION, PER...   \n",
       "2  business  003.txt  [ORGANIZATION, OTHER, ORGANIZATION, QUANTITY, ...   \n",
       "3  business  004.txt  [ORGANIZATION, ORGANIZATION, QUANTITY, QUANTIT...   \n",
       "4  business  005.txt  [ORGANIZATION, ORGANIZATION, LOCATION, ORGANIZ...   \n",
       "\n",
       "                                            aws_text  \\\n",
       "0  [Time Warner, US, TimeWarner, 76%, $1.13bn, £6...   \n",
       "1  [Greenspan, almost three months, Federal Reser...   \n",
       "2  [Yukos, Russian, Yukos, $900m, Â£479m, Rosneft...   \n",
       "3  [BA, British Airways, 40%, three months, 31 De...   \n",
       "4  [Pernod, Domecq, UK, Allied Domecq, France, Pe...   \n",
       "\n",
       "                                        spacy_entity  \\\n",
       "0  [ORG, GPE, ORG, PERCENT, MONEY, ORG, DATE, MON...   \n",
       "1  [PERSON, DATE, ORG, GPE, PERSON, GPE, GPE, MON...   \n",
       "2  [NORP, PRODUCT, MONEY, ORG, ORG, GPE, MONEY, G...   \n",
       "3  [ORG, PERCENT, DATE, MONEY, GPE, DATE, PERSON,...   \n",
       "4  [ORG, GPE, ORG, GPE, ORG, ORG, ORG, NORP, ORG,...   \n",
       "\n",
       "                                          spacy_text  \n",
       "0  [Time Warner, US, TimeWarner, 76%, 1.13bn, Â£6...  \n",
       "1  [Greenspan, almost three months, the Federal R...  \n",
       "2  [Russian, Yukos, $900m, State, Rosneft, Yugans...  \n",
       "3  [BA, 40%, the three months to 31 December 2004...  \n",
       "4  [Domecq  , UK, Allied Domecq, France, Pernod R...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store all the info in a dataframe\n",
    "\n",
    "df_ents = pd.DataFrame()\n",
    "df_ents[\"label\"] = label\n",
    "df_ents[\"filename\"] = file_name\n",
    "df_ents[\"aws_entity\"] = aws_ent_label\n",
    "df_ents[\"aws_text\"] = aws_ent_text\n",
    "df_ents[\"spacy_entity\"] = spacy_ent_label\n",
    "df_ents[\"spacy_text\"] = spacy_ent_text\n",
    "\n",
    "\n",
    "\n",
    "df_ents.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_unique_text = []\n",
    "spacy_unique_text = []\n",
    "aws_unique_ent = []\n",
    "spacy_unique_ent = []\n",
    "for i in range(len(spacy_ent_text)):\n",
    "    #store the entity content\n",
    "    s1_text = set(spacy_ent_text[i])\n",
    "    s2_text = set(aws_ent_text[i])\n",
    "\n",
    "    #store the type of entity\n",
    "    s1_ent_label = set(spacy_ent_label[i])\n",
    "    s2_ent_label = set(aws_ent_label[i])\n",
    "    \n",
    "    if len(s1_text) < len(s2_text):\n",
    "        aws_unique_text.append(set(s2_text-s1_text))\n",
    "        spacy_unique_text.append(\"\")\n",
    "        aws_unique_ent.append(set(s2_ent_label - s1_ent_label))\n",
    "        spacy_unique_ent.append(\"\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aws_uniqe_ent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-f541d1d5a8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0maws_unique_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_text\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms1_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mspacy_unique_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0maws_uniqe_ent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_ent_label\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms1_ent_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mspacy_unique_ent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aws_uniqe_ent' is not defined"
     ]
    }
   ],
   "source": [
    "aws_unique_text = []\n",
    "spacy_unique_text = []\n",
    "aws_unique_ent = []\n",
    "spacy_unique_ent = []\n",
    "for i in range(len(spacy_ent_text)):\n",
    "    #store the entity content\n",
    "    s1_text = set(spacy_ent_text[i])\n",
    "    s2_text = set(aws_ent_text[i])\n",
    "    \n",
    "    #store the type of entity\n",
    "    s1_ent_label = set(spacy_ent_label[i])\n",
    "    s2_ent_label = set(aws_ent_label[i])\n",
    "    if len(s1_text) < len(s2_text):\n",
    "        aws_unique_text.append(set(s2_text-s1_text))\n",
    "        spacy_unique_text.append(\"\")\n",
    "        aws_uniqe_ent.append(set(s2_ent_label - s1_ent_label))\n",
    "        spacy_unique_ent.append(\"\")\n",
    "    else:\n",
    "        spacy_unique_text.append(set(s1_text-s2_text))\n",
    "        aws_unique_text.append(\"\")\n",
    "        spacy_unique_ent.append(set(s1_ent_label - s2_ent_label))\n",
    "        aws_unique_ent.append(\"\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-3e287b7eaa63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_text\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms1_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0maws_unique_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0maws_unique_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mspacy_unique_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mspacy_unique_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-99-3e287b7eaa63>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_text\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms1_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0maws_unique_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0maws_unique_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mspacy_unique_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mspacy_unique_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "#create a diff between spacy and comprehend entities by finding unique entities\n",
    "\n",
    "aws_unique_text = []\n",
    "spacy_unique_text = []\n",
    "aws_unique_label = []\n",
    "spacy_unique_text = []\n",
    "for i in range(len(spacy_ent_text)):\n",
    "    #store the entity content\n",
    "    s1_text = set(spacy_ent_text[i])\n",
    "    s2_text = set(aws_ent_text[i])\n",
    "    \n",
    "    #store the type of entity\n",
    "    s1_ent_label = set(spacy_ent_label[i])\n",
    "    s2_ent_label = set(aws_ent_label[i])\n",
    "    if len(s1_text) < len(s2_text):\n",
    "        diff = set(s2_text - s1_text)\n",
    "        aws_unique_text.append(diff)\n",
    "        aws_unique_label.append([x['Type'] for x in diff])\n",
    "        spacy_unique_text.append(\"\")\n",
    "        spacy_unique_label.append(\"\")\n",
    "    else:\n",
    "        diff = set(s1_text - s2_text)\n",
    "        spacy_unique_text.append(diff)\n",
    "        spacy_unique_label.append(x.label_ for x in diff)\n",
    "        aws_unique_text.append(\"\")\n",
    "        aws_unique_text.append(\"\")\n",
    "        \n",
    "        \n",
    "    \n",
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"label\"] = label\n",
    "df[\"filename\"] = file_name\n",
    "df[\"spacy_unique_label\"] = spacy_unique_label\n",
    "df[\"spacy_unique_text\"] = spacy_unique_text\n",
    "df[\"aws_unique_label\"] = aws_unique_label\n",
    "df[\"aws_unique_text\"] = aws_unique_text\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>spacy_unique_text</th>\n",
       "      <th>aws_unique_text</th>\n",
       "      <th>intersection_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td></td>\n",
       "      <td>{$500m, fourth quarter profits, $3.36bn, £600m...</td>\n",
       "      <td>{third, TimeWarner, 27%, 6.4%, three quarters,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>{The White House, a quarter, as many months, 1...</td>\n",
       "      <td></td>\n",
       "      <td>{this year, European, Chinese, Monday, almost ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>{540, 9.3bn, 27.5bn, Yukos', State, Menatep Gr...</td>\n",
       "      <td></td>\n",
       "      <td>{Rosneft, Russia, Russian, Menatep Group, Yuga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td></td>\n",
       "      <td>{£75m, £59m, 13,000 jobs, 31 December 2004, £6...</td>\n",
       "      <td>{BA, October, Dresdner Kleinwort Wasserstein, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td></td>\n",
       "      <td>{third, Dunkin' Donuts, Creek wine, 8.2bn euro...</td>\n",
       "      <td>{Scotland, 4%, 1.2%, Allied, London, two, Pari...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label filename                                  spacy_unique_text  \\\n",
       "0  business  001.txt                                                      \n",
       "1  business  002.txt  {The White House, a quarter, as many months, 1...   \n",
       "2  business  003.txt  {540, 9.3bn, 27.5bn, Yukos', State, Menatep Gr...   \n",
       "3  business  004.txt                                                      \n",
       "4  business  005.txt                                                      \n",
       "\n",
       "                                     aws_unique_text  \\\n",
       "0  {$500m, fourth quarter profits, $3.36bn, £600m...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3  {£75m, £59m, 13,000 jobs, 31 December 2004, £6...   \n",
       "4  {third, Dunkin' Donuts, Creek wine, 8.2bn euro...   \n",
       "\n",
       "                                   intersection_text  \n",
       "0  {third, TimeWarner, 27%, 6.4%, three quarters,...  \n",
       "1  {this year, European, Chinese, Monday, almost ...  \n",
       "2  {Rosneft, Russia, Russian, Menatep Group, Yuga...  \n",
       "3  {BA, October, Dresdner Kleinwort Wasserstein, ...  \n",
       "4  {Scotland, 4%, 1.2%, Allied, London, two, Pari...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find intersection\n",
    "intersection_text = []\n",
    "for i in range(len(spacy_ent_text)):\n",
    "    #store the entity content\n",
    "    s1_text = set(spacy_ent_text[i])\n",
    "    s2_text = set(aws_ent_text[i])\n",
    "    \n",
    "    #store the type of entity\n",
    "    s1_ent_label = set(spacy_ent_label[i])\n",
    "    \n",
    "    intersection_text.append(s1_text.intersection(s2_text))\n",
    "\n",
    "df['intersection_text'] = intersection_text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"aws_spacy_comparison.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
